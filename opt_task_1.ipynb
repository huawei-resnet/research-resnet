{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making cycle for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully download file cv-course-public/coding-1/cifar-10-python.tar.gz from OBS to local ./data/cifar-10-python.tar.gz\n",
      "Successfully download file cv-course-public/coding-1/cifar-100-python.tar.gz from OBS to local ./data/cifar-100-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from tnt_solver_ import *\n",
    "# from models.resnet10_ import resnet10_20, resnet10_56, resnet10_110\n",
    "# from models.resnet100_ import resnet100_20, resnet100_56, resnet100_110\n",
    "from dataset.dataset_dowloader_ import *\n",
    "\n",
    "cifar10_dowloader()\n",
    "cifar100_dowloader()\n",
    "# model = resnet20()\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchnet==0.0.4 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from -r requirements.txt (line 1))\n",
      "Requirement already satisfied: tqdm==4.40.1 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from -r requirements.txt (line 2))\n",
      "Requirement already satisfied: pandas==0.25.3 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from -r requirements.txt (line 3))\n",
      "Requirement already satisfied: scikit-learn==0.22 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from -r requirements.txt (line 4))\n",
      "Requirement already satisfied: Keras==2.3.1 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from -r requirements.txt (line 5))\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: torch in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: visdom in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from scikit-learn==0.22->-r requirements.txt (line 4))\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from scikit-learn==0.22->-r requirements.txt (line 4))\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from Keras==2.3.1->-r requirements.txt (line 5))\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from Keras==2.3.1->-r requirements.txt (line 5))\n",
      "Requirement already satisfied: pyyaml in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from Keras==2.3.1->-r requirements.txt (line 5))\n",
      "Requirement already satisfied: h5py in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from Keras==2.3.1->-r requirements.txt (line 5))\n",
      "Requirement already satisfied: tornado in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: websocket-client in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: pyzmq in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: torchfile in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: jsonpatch in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: pillow in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from jsonpatch->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "# !mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# from models.resnet_n import resnet_n\n",
    "\n",
    "from auto_resnet import * # def with auto layers (20, 56, 110) and classes (10, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with ResNet20 CIFAR100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ResNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (1): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (2): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): _BasicBlock(\n",
      "      (down_sampler): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (1): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (2): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): _BasicBlock(\n",
      "      (down_sampler): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (1): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (2): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=100, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 1/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:13<00:00, 47.71it/s, loss:4.4994, acc:2.1000%]\n",
      "Val loss: 4.3606, accuracy: 3.52%\n",
      "Epoch: 2/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 49.79it/s, loss:4.1700, acc:5.2700%]\n",
      "Val loss: 4.2017, accuracy: 6.03%\n",
      "Epoch: 3/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 49.35it/s, loss:4.0230, acc:7.7250%]\n",
      "Val loss: 3.9845, accuracy: 8.95%\n",
      "Epoch: 4/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.76it/s, loss:3.9112, acc:9.2675%]\n",
      "Val loss: 3.8682, accuracy: 10.97%\n",
      "Epoch: 5/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.93it/s, loss:3.8117, acc:10.7250%]\n",
      "Val loss: 4.1820, accuracy: 9.51%\n",
      "Epoch: 6/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.61it/s, loss:3.7177, acc:12.1100%]\n",
      "Val loss: 3.6910, accuracy: 12.38%\n",
      "Epoch: 7/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.63it/s, loss:3.6118, acc:13.8200%]\n",
      "Val loss: 3.6592, accuracy: 14.47%\n",
      "Epoch: 8/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.95it/s, loss:3.5296, acc:15.0650%]\n",
      "Val loss: 3.7853, accuracy: 12.60%\n",
      "Epoch: 9/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.95it/s, loss:3.4696, acc:16.1450%]\n",
      "Val loss: 3.6410, accuracy: 12.51%\n",
      "Epoch: 10/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:13<00:00, 47.79it/s, loss:3.4121, acc:16.7875%]\n",
      "Val loss: 3.3638, accuracy: 18.02%\n",
      "Epoch: 11/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 49.30it/s, loss:3.3715, acc:17.4125%]\n",
      "Val loss: 3.8984, accuracy: 14.60%\n",
      "Epoch: 12/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.51it/s, loss:3.3263, acc:18.2650%]\n",
      "Val loss: 3.4934, accuracy: 16.42%\n",
      "Epoch: 13/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.93it/s, loss:3.2944, acc:18.5400%]\n",
      "Val loss: 3.7603, accuracy: 14.38%\n",
      "Epoch: 14/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.63it/s, loss:3.2761, acc:18.8200%]\n",
      "Val loss: 3.5955, accuracy: 16.03%\n",
      "Epoch: 15/180, lr:1.00e+00\n",
      "100%|██████████| 625/625 [00:12<00:00, 48.62it/s, loss:3.2622, acc:19.3850%]\n",
      "Val loss: 3.5246, accuracy: 16.26%\n",
      "Epoch: 16/180, lr:1.00e+00\n",
      "  0%|          | 0/625 [00:00<?, ?it/s, loss:3.5088, acc:9.3750%]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tnt_solver_ import *\n",
    "# from models.resnet_n import resnet_n\n",
    "\n",
    "# lr_cycle = \n",
    "history_lr = []\n",
    "legend_lr = ['lr_10', 'lr_5', 'lr_2', 'lr_0.1', 'lr_0.2', 'lr_0.5']\n",
    "for lr_i in [10, 5, 2, 0.1, 0.2, 0.5]:\n",
    "    # resnet20, cifar100\n",
    "    auto_resnet(20, 100, lr_i, 180, history_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
      "    send_bytes(obj)\n",
      "  File \"/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
      "    self._send_bytes(m[offset:offset + size])\n",
      "  File \"/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
      "    self._send(header + buf)\n",
      "  File \"/home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
      "    n = write(self._handle, buf)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6798b520c5fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt_different_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/work/research-resnet/auto_resnet.py\u001b[0m in \u001b[0;36mplt_different_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplt_different_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# train_loss for resnet 20, 56, 110 with cifar10/100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'orange'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'purple'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 288/625 [00:19<00:06, 52.88it/s, loss:2.1384, acc:18.7771%]"
     ]
    }
   ],
   "source": [
    "plt_different_history(history_lr, legend_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Note that the learning rate policy should be adjusted accordingly\n",
    "history_epochs = []\n",
    "legend_epochs = ['epoch_/1', 'epoch_/2', 'epoch_/0.5']\n",
    "\n",
    "for lr_i in [1, 2, 0.5]:\n",
    "    auto_resnet(20, 100, lr_i, 180/lr_i, history_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_different_history(history_epochs, legend_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different part of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Note that the learning rate policy should be adjusted accordingly ??\n",
    "history_batch = []\n",
    "legend_batch = ['0.8x128', '0.8x64', '0.8x32', '0.5x128', '0.5x64', '0.5x32', '0.2x128', '0.2x64', '0.2x32']\n",
    "for data_part_i in [0.8, 0.5, 0.2]:\n",
    "    for batch_i in [128, 64, 32]:\n",
    "        # resnet20, cifar100\n",
    "        auto_resnet(20, 100, 1, 180, history_batch, data_part_i, batch_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_different_history(history_batch, legend_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
