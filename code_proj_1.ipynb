{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet && CIFAR10/CIFAR100\n",
    "We test ResNet classifier.\n",
    "First init some basic environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One time installation of needed lib from requirement.txt and creating dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchnet==0.0.4 (from -r requirements.txt (line 1))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/b7/b2/d7f70a85d3f6b0365517782632f150e3bbc2fb8e998cd69e27deba599aae/torchnet-0.0.4.tar.gz\n",
      "Collecting tqdm==4.40.1 (from -r requirements.txt (line 2))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/71/b0/6d63e33dbf5935dccd334ee2b83cc4d3828817de6faaa3a3f7f5b8cc5141/tqdm-4.40.1-py2.py3-none-any.whl (55kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 70.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.25.3 (from -r requirements.txt (line 3))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.4MB 98.3MB/s eta 0:00:01  27% |████████▊                       | 2.8MB 93.9MB/s eta 0:00:01   69% |██████████████████████▏         | 7.2MB 89.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn==0.22 (from -r requirements.txt (line 4))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/2e/d0/860c4f6a7027e00acff373d9f5327f4ae3ed5872234b3cbdd7bcb52e5eff/scikit_learn-0.22-cp36-cp36m-manylinux1_x86_64.whl (7.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.0MB 89.4MB/s ta 0:00:011�██████████████████▊          | 4.8MB 88.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Keras==2.3.1 (from -r requirements.txt (line 5))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl (377kB)\n",
      "\u001b[K    100% |████████████████████████████████| 378kB 100.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: six in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Collecting visdom (from torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
      "\u001b[K    100% |████████████████████████████████| 686kB 44.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from pandas==0.25.3->-r requirements.txt (line 3))\n",
      "Requirement already satisfied: scipy>=0.17.0 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from scikit-learn==0.22->-r requirements.txt (line 4))\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from scikit-learn==0.22->-r requirements.txt (line 4))\n",
      "Collecting keras-preprocessing>=1.0.5 (from Keras==2.3.1->-r requirements.txt (line 5))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 69.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from Keras==2.3.1->-r requirements.txt (line 5))\n",
      "Requirement already satisfied: pyyaml in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from Keras==2.3.1->-r requirements.txt (line 5))\n",
      "Collecting keras-applications>=1.0.6 (from Keras==2.3.1->-r requirements.txt (line 5))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 68.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: tornado in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: pyzmq in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Collecting jsonpatch (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/86/7e/035d19a73306278673039f0805b863be8798057cc1b4008b9c8c7d1d32a3/jsonpatch-1.24-py2.py3-none-any.whl\n",
      "Collecting torchfile (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
      "Collecting websocket-client (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
      "\u001b[K    100% |████████████████████████████████| 204kB 99.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages (from requests->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch->visdom->torchnet==0.0.4->-r requirements.txt (line 1))\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: torchnet, visdom, torchfile\n",
      "  Running setup.py bdist_wheel for torchnet ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ma-user/.cache/pip/wheels/54/7e/85/0e5071d02c5d0cf37cfd9fd437b71a2281fb71b1f89197edc5\n",
      "  Running setup.py bdist_wheel for visdom ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ma-user/.cache/pip/wheels/97/83/ee/4e0ef1aaffc3f1a81caa2bef44df43a1dd42ebcd3fbe99096e\n",
      "  Running setup.py bdist_wheel for torchfile ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ma-user/.cache/pip/wheels/3f/13/e6/01b1c6b1d3a90163bf6a9efaec1ca4a95f519220a93aa7ce81\n",
      "Successfully built torchnet visdom torchfile\n",
      "Installing collected packages: jsonpointer, jsonpatch, torchfile, websocket-client, visdom, torchnet, tqdm, pandas, scikit-learn, keras-preprocessing, keras-applications, Keras\n",
      "  Found existing installation: tqdm 4.28.1\n",
      "    Uninstalling tqdm-4.28.1:\n",
      "      Successfully uninstalled tqdm-4.28.1\n",
      "  Found existing installation: pandas 0.22.0\n",
      "    Uninstalling pandas-0.22.0:\n",
      "      Successfully uninstalled pandas-0.22.0\n",
      "  Found existing installation: scikit-learn 0.19.1\n",
      "    Uninstalling scikit-learn-0.19.1:\n",
      "      Successfully uninstalled scikit-learn-0.19.1\n",
      "Successfully installed Keras-2.3.1 jsonpatch-1.24 jsonpointer-2.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 pandas-0.25.3 scikit-learn-0.22 torchfile-0.1.0 torchnet-0.0.4 tqdm-4.40.1 visdom-0.1.8.9 websocket-client-0.56.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 9.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "mkdir: cannot create directory ‘data’: File exists\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet20/56/110 model with CIFAR10 / CIFAR100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully download file cv-course-public/coding-1/cifar-10-python.tar.gz from OBS to local ./data/cifar-10-python.tar.gz\n",
      "Successfully download file cv-course-public/coding-1/cifar-100-python.tar.gz from OBS to local ./data/cifar-100-python.tar.gz\n",
      "_ResNet(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (1): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (2): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): _BasicBlock(\n",
      "      (down_sampler): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (1): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (2): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): _BasicBlock(\n",
      "      (down_sampler): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (1): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "    (2): _BasicBlock(\n",
      "      (conv_bn_relu1): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace)\n",
      "      )\n",
      "      (conv_bn2): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (relu_out): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from tnt_solver_ import *\n",
    "from models.resnet_ import resnet20, resnet56, resnet110\n",
    "from dataset.dataset_dowloader_ import *\n",
    "\n",
    "cifar10_dowloader()\n",
    "cifar100_dowloader()\n",
    "model = resnet20()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start learning \n",
    "\n",
    "## TODO\n",
    "+ Stohastic gradient decrease? May be adam?\n",
    "+ lr?\n",
    "+ epoch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.functional as F\n",
    "# opt = optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=1e-4, nesterov=False)\n",
    "# loss_fn = F.cross_entropy\n",
    "\n",
    "# lr_scheduler= optim.lr_scheduler.MultiStepLR(opt, milestones=[91, 137], gamma=0.1)\n",
    "# history = main(model, opt, epoch=180, loss_fn=loss_fn, lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GREAT TODO\n",
    "+ Test each modification 3 times for the average results\n",
    "+ Solve some of todos above\n",
    "+ Play with lr, epochs, STD\n",
    "+ Graphics\n",
    "+ Think about the best way to analyse all results\n",
    "+ May be to play with VGG?\n",
    "+ Why with classic startup options there is over learning after 90th epoch???\n",
    "\n",
    "Control each model learning startup to re-define all weights. (maybe) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "d = { \"lrate\" : [0.01, 0.001, 0.0001],\n",
    "  \"epochs\": [10, 20, 30],\n",
    "  \"optimizer\": [\"Adam\", \"SGD\", \"Adadelta\"]\n",
    "}\n",
    "\n",
    "# params = {\n",
    "#     'lr': [0.01, 0.02],\n",
    "#     'max_epochs': [10, 20],\n",
    "# }\n",
    "params = {\n",
    "    'epoch': [10, 20],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(d)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(lrate, epochs, optimizer):\n",
    "    print(lrate, epochs, optimizer)\n",
    "    return 'GOVNO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i, (lrate, epochs, optimizer) in df.iterrows():\n",
    "    models.append(train_model(lrate, epochs, optimizer))\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "# parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "# svc = svm.SVC()\n",
    "# clf = GridSearchCV(svc, parameters)\n",
    "# clf.fit(iris.data, iris.target)\n",
    "\n",
    "clf = GridSearchCV(main, params)\n",
    "clf.fit(iris.data, iris.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torchnet as tnt\n",
    "from torchnet.engine import Engine\n",
    "from dataset.data_loader_ import CIFAR10Data\n",
    "# from torchnet.logger import VisdomLogger, VisdomPlotLogger\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from models.resnet_ import resnet20, resnet56, resnet110\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from config.config_ import mean, std\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"\n",
    "    plot loss and acc history.\n",
    "    :param history: train returned history object\n",
    "    \"\"\"\n",
    "    plt.plot(history['train_loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Loss value')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history['train_acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('acc value')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history['train_lr'])\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('Train LR')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main(model, opt, epoch, loss_fn=F.cross_entropy, lr_scheduler=None):\n",
    "    \"\"\"\n",
    "    train model and test on test data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    torch.manual_seed(6666)\n",
    "    torch.cuda.manual_seed(6666)\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    model.to(device)\n",
    "    \n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.RandomCrop(size=(32, 32), padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "    train_set = torchvision.datasets.cifar.CIFAR10('data/', train=True, download=True, transform=train_transform)\n",
    "    val_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=val_transform)\n",
    "\n",
    "    train_split=0.9\n",
    "    num_train = len(train_set)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(num_train * train_split)\n",
    "    train_idx, val_idx = indices[:split], indices[split:]\n",
    "    train_dataset = torch.utils.data.Subset(train_set, train_idx)\n",
    "    print(type(train_dataset))\n",
    "    print(type(train_dataset.dataset))\n",
    "    print(type(train_dataset.dataset[0]))\n",
    "    print(train_dataset.dataset[0])\n",
    "    print(type(train_dataset.dataset[0][0]))\n",
    "    print(type(train_dataset.dataset[0][1]))\n",
    "    \n",
    "    val_dataset = torch.utils.data.Subset(val_set, val_idx)\n",
    "\n",
    "    X = (np.swapaxes(train_set.train_data, 1, 3)/255).astype('float32')\n",
    "    y = np.array(val_set.train_labels).astype('int64')\n",
    "    print(X.shape)\n",
    "    print(y.shape)\n",
    "    print(X[0])\n",
    "    print(y[0])\n",
    "    \n",
    "#     net1 = ResnetClassifier(1)\n",
    "#     net1.fit(X,y)\n",
    "    \n",
    "    net = ResnetClassifier()\n",
    "    \n",
    "    tuned_params = {\"epoches\" : [1,3]}\n",
    "\n",
    "    gs = GridSearchCV(estimator=net, param_grid=tuned_params, refit=False, cv=3, scoring='accuracy')\n",
    "#     gs.fit(train_set, val_set)\n",
    "    gs.fit(X, y)\n",
    "#     gs.fit(train_dataset, val_dataset)\n",
    "    best_score = gs.best_score_\n",
    "    best_params = gs.best_params_\n",
    "    \n",
    "class ResnetClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"An example of classifier\"\"\"\n",
    "\n",
    "    def __init__(self, epoches=0):\n",
    "        \"\"\"\n",
    "        Called when initializing the classifier\n",
    "        \"\"\"\n",
    "        self.epoches = epoches\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        This should fit classifier. All the \"work\" should be done here.\n",
    "\n",
    "        Note: assert is not a good choice here and you should rather\n",
    "        use try/except blog with exceptions. This is just for short syntax.\n",
    "        \"\"\"\n",
    "#         train_split=0.9\n",
    "\n",
    "#         num_train = len(X)\n",
    "#         indices = list(range(num_train))\n",
    "#         split = int(num_train * train_split)\n",
    "#         train_idx, val_idx = indices[:split], indices[split:]\n",
    "#         train_dataset = torch.utils.data.Subset(X, train_idx)\n",
    "#         val_dataset = torch.utils.data.Subset(y, val_idx)\n",
    "#         test_dataset = val_dataset\n",
    "\n",
    "        print(X.shape[0])\n",
    "        a = []\n",
    "        for i in range(X.shape[0]):\n",
    "            b = (torch.from_numpy(X[i]),y[i])\n",
    "            a.append(b)\n",
    "        print(a)\n",
    "#         print(type(X.dataset[0]))\n",
    "#         print(X.dataset[0])\n",
    "#         print(X.dataset[1])\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            a, batch_size=128,\n",
    "            num_workers=2, shuffle=True)\n",
    "#         print(type(train_loader.dataset))\n",
    "#         print(train_loader.dataset[0].shape)\n",
    "#         print(train_loader.dataset[1].shape)\n",
    "        \n",
    "        val_loader = torch.utils.data.DataLoader(\n",
    "            a, batch_size=128,\n",
    "            num_workers=2, shuffle=False\n",
    "        )\n",
    "            \n",
    "        test_loader = torch.utils.data.DataLoader(\n",
    "            a, batch_size=128,\n",
    "            num_workers=2, shuffle=False\n",
    "        )\n",
    "              \n",
    "#         print(train_loader.dataset.size())\n",
    "#         print(val_loader.dataset.size())\n",
    "        \n",
    "        num_classes = 10\n",
    "        lr_scheduler = None\n",
    "        \n",
    "        self.model = resnet20()\n",
    "\n",
    "        self.loss_fn = F.cross_entropy\n",
    "\n",
    "        torch.manual_seed(6666)\n",
    "        torch.cuda.manual_seed(6666)\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda:0')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        self.model.to(device)\n",
    "        history = {'train_loss': [], 'train_acc': [], 'train_lr': [], 'val_loss': [], 'val_acc': []}\n",
    "        \n",
    "        opt = optim.SGD(self.model.parameters(), lr=1e-1, momentum=0.9, weight_decay=1e-4, nesterov=False)\n",
    "\n",
    "        meter_loss = tnt.meter.AverageValueMeter()\n",
    "        self.classacc = tnt.meter.ClassErrorMeter(accuracy=True)\n",
    "        confusion_meter = tnt.meter.ConfusionMeter(num_classes, normalized=True)\n",
    "\n",
    "        def reset_meters():\n",
    "            self.classacc.reset()\n",
    "            meter_loss.reset()\n",
    "\n",
    "        def on_forward(state):\n",
    "            self.classacc.add(state['output'].detach(), state['sample'][1])\n",
    "            meter_loss.add(state['loss'].item())\n",
    "            confusion_meter.add(state['output'].detach(), state['sample'][1])\n",
    "            if state['train']:\n",
    "                state['iterator'].set_postfix_str(s=\"loss:{:.4f}, acc:{:.4f}%\".format(meter_loss.value()[0], self.classacc.value()[0]))\n",
    "        def on_start_epoch(state):\n",
    "            current_lr = opt.param_groups[0]['lr']\n",
    "            print('Epoch: %d/%d, lr:%.2e' % (state['epoch']+1, state['maxepoch'], current_lr))\n",
    "            reset_meters()\n",
    "            self.model.train(True)\n",
    "            state['iterator'] = tqdm(state['iterator'], file=sys.stdout)\n",
    "            history['train_lr'].append(current_lr)\n",
    "\n",
    "        def on_end_epoch(state):\n",
    "            history['train_loss'].append(meter_loss.value()[0])\n",
    "            history['train_acc'].append(self.classacc.value()[0])\n",
    "\n",
    "            # do validation at the end of each epoch\n",
    "            reset_meters()\n",
    "            self.model.train(False)\n",
    "            engine.test(h, val_loader)\n",
    "            print('Val loss: %.4f, accuracy: %.2f%%' % (meter_loss.value()[0], self.classacc.value()[0]))\n",
    "\n",
    "            if lr_scheduler:\n",
    "                if isinstance(lr_scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                    lr_scheduler.step(self.classacc.value()[0], epoch=(epoch+1))\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "            history['val_loss'].append(meter_loss.value()[0])\n",
    "            history['val_acc'].append(self.classacc.value()[0])\n",
    "            \n",
    "        def h(sample):\n",
    "            x = sample[0].to(device)\n",
    "#             print(type(sample))\n",
    "#             print(sample.shape)\n",
    "#             print(type(x))\n",
    "#             print(x.shape)\n",
    "            y = sample[1].to(device)\n",
    "#             print(type(y))\n",
    "#             print(y.shape)\n",
    "            o = self.model(x.cuda())\n",
    "            return self.loss_fn(o, y), o\n",
    "\n",
    "        engine = Engine()\n",
    "        engine.hooks['on_forward'] = on_forward\n",
    "        engine.hooks['on_start_epoch'] = on_start_epoch\n",
    "        engine.hooks['on_end_epoch'] = on_end_epoch\n",
    "        engine.train(h, train_loader, self.epoches, opt)\n",
    "\n",
    "        # test\n",
    "        self.model.train(False)\n",
    "        engine.test(h, test_loader)\n",
    "        print('Test loss: %.4f, accuracy: %.2f%%' % (meter_loss.value()[0], self.classacc.value()[0]))\n",
    "        plot_history(history)\n",
    "        return self        \n",
    "        \n",
    "    def predict(self, X=None, y=None):\n",
    "        print(X)\n",
    "        print(type(X))\n",
    "        print(y)\n",
    "        print(type(y))\n",
    "        print(torch.from_numpy(X).shape)\n",
    "#         o = self.model(torch.from_numpy(X))\n",
    "        return([])\n",
    "\n",
    "    def score(self, X=None, y=None):\n",
    "        # counts number of values bigger than mean\n",
    "        return self.classacc.value()[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "<class 'torch.utils.data.dataset.Subset'>\n",
      "<class 'torchvision.datasets.cifar.CIFAR10'>\n",
      "<class 'tuple'>\n",
      "(tensor([[[-1.7358, -1.2120, -0.6722,  ..., -0.0849, -0.2595, -1.9898],\n",
      "         [-1.3866, -0.6087, -0.3071,  ..., -0.0690, -0.4976, -1.9898],\n",
      "         [-1.0532, -0.3706,  0.0263,  ..., -0.7992, -0.9262, -1.9898],\n",
      "         ...,\n",
      "         [ 0.6771,  0.8518,  0.9946,  ...,  0.4073, -0.0372, -1.9898],\n",
      "         [-1.9898, -1.9898, -1.9898,  ..., -1.9898, -1.9898, -1.9898],\n",
      "         [-1.9898, -1.9898, -1.9898,  ..., -1.9898, -1.9898, -1.9898]],\n",
      "\n",
      "        [[-1.8674, -1.5452, -1.1748,  ..., -0.6272, -0.8044, -1.9801],\n",
      "         [-1.6580, -1.1104, -0.9654,  ..., -0.6111, -0.9815, -1.9801],\n",
      "         [-1.4647, -0.9332, -0.7077,  ..., -1.2231, -1.3036, -1.9801],\n",
      "         ...,\n",
      "         [ 0.0976,  0.3069,  0.4197,  ..., -0.0796, -0.4983, -1.9801],\n",
      "         [-1.9801, -1.9801, -1.9801,  ..., -1.9801, -1.9801, -1.9801],\n",
      "         [-1.9801, -1.9801, -1.9801,  ..., -1.9801, -1.9801, -1.9801]],\n",
      "\n",
      "        [[-1.7066, -1.5867, -1.3618,  ..., -0.9570, -1.0770, -1.7066],\n",
      "         [-1.6466, -1.3318, -1.2868,  ..., -0.9870, -1.1819, -1.7066],\n",
      "         [-1.5417, -1.1969, -1.1219,  ..., -1.3618, -1.3318, -1.7066],\n",
      "         ...,\n",
      "         [-0.2974, -0.4024, -0.7022,  ..., -0.4473, -0.6272, -1.7066],\n",
      "         [-1.7066, -1.7066, -1.7066,  ..., -1.7066, -1.7066, -1.7066],\n",
      "         [-1.7066, -1.7066, -1.7066,  ..., -1.7066, -1.7066, -1.7066]]]), 6)\n",
      "<class 'torch.Tensor'>\n",
      "<class 'int'>\n",
      "(50000, 3, 32, 32)\n",
      "(50000,)\n",
      "[[[0.23137255 0.0627451  0.09803922 ... 0.8156863  0.7058824  0.69411767]\n",
      "  [0.16862746 0.         0.0627451  ... 0.7882353  0.6784314  0.65882355]\n",
      "  [0.19607843 0.07058824 0.19215687 ... 0.7764706  0.7294118  0.7019608 ]\n",
      "  ...\n",
      "  [0.61960787 0.48235294 0.4627451  ... 0.627451   0.72156864 0.84705883]\n",
      "  [0.59607846 0.46666667 0.47058824 ... 0.21960784 0.38039216 0.5921569 ]\n",
      "  [0.5803922  0.47843137 0.42745098 ... 0.20784314 0.3254902  0.48235294]]\n",
      "\n",
      " [[0.24313726 0.07843138 0.09411765 ... 0.6666667  0.54509807 0.5647059 ]\n",
      "  [0.18039216 0.         0.02745098 ... 0.6        0.48235294 0.5058824 ]\n",
      "  [0.1882353  0.03137255 0.10588235 ... 0.6313726  0.5647059  0.5568628 ]\n",
      "  ...\n",
      "  [0.5176471  0.34509805 0.32941177 ... 0.52156866 0.5803922  0.72156864]\n",
      "  [0.49019608 0.3254902  0.32941177 ... 0.12156863 0.24313726 0.4627451 ]\n",
      "  [0.4862745  0.34117648 0.28627452 ... 0.13333334 0.20784314 0.36078432]]\n",
      "\n",
      " [[0.24705882 0.07843138 0.08235294 ... 0.3764706  0.3764706  0.45490196]\n",
      "  [0.1764706  0.         0.         ... 0.13333334 0.16470589 0.36862746]\n",
      "  [0.16862746 0.         0.03137255 ... 0.10196079 0.11764706 0.34117648]\n",
      "  ...\n",
      "  [0.42352942 0.21568628 0.19607843 ... 0.27450982 0.36862746 0.54901963]\n",
      "  [0.4        0.19607843 0.19607843 ... 0.02745098 0.13333334 0.32941177]\n",
      "  [0.40392157 0.22352941 0.16470589 ... 0.07843138 0.13333334 0.28235295]]]\n",
      "6\n",
      "33333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 261/261 [00:06<00:00, 38.00it/s, loss:1.6692, acc:36.9784%]\n",
      "Val loss: 1.5577, accuracy: 41.33%\n",
      "Test loss: 1.5577, accuracy: 41.33%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.23137255 0.0627451  0.09803922 ... 0.8156863  0.7058824\n",
      "    0.69411767]\n",
      "   [0.16862746 0.         0.0627451  ... 0.7882353  0.6784314\n",
      "    0.65882355]\n",
      "   [0.19607843 0.07058824 0.19215687 ... 0.7764706  0.7294118\n",
      "    0.7019608 ]\n",
      "   ...\n",
      "   [0.61960787 0.48235294 0.4627451  ... 0.627451   0.72156864\n",
      "    0.84705883]\n",
      "   [0.59607846 0.46666667 0.47058824 ... 0.21960784 0.38039216\n",
      "    0.5921569 ]\n",
      "   [0.5803922  0.47843137 0.42745098 ... 0.20784314 0.3254902\n",
      "    0.48235294]]\n",
      "\n",
      "  [[0.24313726 0.07843138 0.09411765 ... 0.6666667  0.54509807\n",
      "    0.5647059 ]\n",
      "   [0.18039216 0.         0.02745098 ... 0.6        0.48235294\n",
      "    0.5058824 ]\n",
      "   [0.1882353  0.03137255 0.10588235 ... 0.6313726  0.5647059\n",
      "    0.5568628 ]\n",
      "   ...\n",
      "   [0.5176471  0.34509805 0.32941177 ... 0.52156866 0.5803922\n",
      "    0.72156864]\n",
      "   [0.49019608 0.3254902  0.32941177 ... 0.12156863 0.24313726\n",
      "    0.4627451 ]\n",
      "   [0.4862745  0.34117648 0.28627452 ... 0.13333334 0.20784314\n",
      "    0.36078432]]\n",
      "\n",
      "  [[0.24705882 0.07843138 0.08235294 ... 0.3764706  0.3764706\n",
      "    0.45490196]\n",
      "   [0.1764706  0.         0.         ... 0.13333334 0.16470589\n",
      "    0.36862746]\n",
      "   [0.16862746 0.         0.03137255 ... 0.10196079 0.11764706\n",
      "    0.34117648]\n",
      "   ...\n",
      "   [0.42352942 0.21568628 0.19607843 ... 0.27450982 0.36862746\n",
      "    0.54901963]\n",
      "   [0.4        0.19607843 0.19607843 ... 0.02745098 0.13333334\n",
      "    0.32941177]\n",
      "   [0.40392157 0.22352941 0.16470589 ... 0.07843138 0.13333334\n",
      "    0.28235295]]]\n",
      "\n",
      "\n",
      " [[[0.6039216  0.54901963 0.54901963 ... 0.6862745  0.64705884\n",
      "    0.6392157 ]\n",
      "   [0.49411765 0.5686275  0.54509807 ... 0.6117647  0.6117647\n",
      "    0.61960787]\n",
      "   [0.4117647  0.49019608 0.4509804  ... 0.6039216  0.62352943\n",
      "    0.6392157 ]\n",
      "   ...\n",
      "   [0.35686275 0.3764706  0.30980393 ... 0.16470589 0.40392157\n",
      "    0.56078434]\n",
      "   [0.34117648 0.3019608  0.26666668 ... 0.23921569 0.48235294\n",
      "    0.56078434]\n",
      "   [0.30980393 0.2784314  0.2627451  ... 0.3647059  0.5137255\n",
      "    0.56078434]]\n",
      "\n",
      "  [[0.69411767 0.627451   0.60784316 ... 0.654902   0.6039216\n",
      "    0.5803922 ]\n",
      "   [0.5372549  0.6        0.57254905 ... 0.6039216  0.59607846\n",
      "    0.5803922 ]\n",
      "   [0.40784314 0.49019608 0.4509804  ... 0.627451   0.6313726\n",
      "    0.6117647 ]\n",
      "   ...\n",
      "   [0.37254903 0.3882353  0.32156864 ... 0.13333334 0.3647059\n",
      "    0.52156866]\n",
      "   [0.3529412  0.3137255  0.27450982 ... 0.20784314 0.44705883\n",
      "    0.5254902 ]\n",
      "   [0.31764707 0.28627452 0.27058825 ... 0.3254902  0.4745098\n",
      "    0.52156866]]\n",
      "\n",
      "  [[0.73333335 0.6627451  0.6431373  ... 0.6509804  0.5019608\n",
      "    0.47058824]\n",
      "   [0.53333336 0.6039216  0.58431375 ... 0.627451   0.50980395\n",
      "    0.47843137]\n",
      "   [0.37254903 0.4627451  0.4392157  ... 0.6666667  0.5568628\n",
      "    0.52156866]\n",
      "   ...\n",
      "   [0.2784314  0.30588236 0.2509804  ... 0.14117648 0.3764706\n",
      "    0.54509807]\n",
      "   [0.2784314  0.24313726 0.21568628 ... 0.22352941 0.47058824\n",
      "    0.5568628 ]\n",
      "   [0.27450982 0.23921569 0.21568628 ... 0.35686275 0.5137255\n",
      "    0.5647059 ]]]\n",
      "\n",
      "\n",
      " [[[1.         1.         1.         ... 0.44313726 0.43529412\n",
      "    0.41568628]\n",
      "   [0.99215686 1.         0.99607843 ... 0.43529412 0.40784314\n",
      "    0.3882353 ]\n",
      "   [0.99215686 1.         0.99607843 ... 0.4117647  0.3882353\n",
      "    0.37254903]\n",
      "   ...\n",
      "   [0.99215686 1.         0.99607843 ... 0.28235295 0.26666668\n",
      "    0.30588236]\n",
      "   [0.99215686 1.         0.99607843 ... 0.28235295 0.27450982\n",
      "    0.30980393]\n",
      "   [0.99215686 1.         0.99607843 ... 0.28235295 0.30588236\n",
      "    0.3137255 ]]\n",
      "\n",
      "  [[1.         1.         1.         ... 0.47058824 0.4627451\n",
      "    0.44313726]\n",
      "   [0.99215686 1.         0.99607843 ... 0.4627451  0.43529412\n",
      "    0.41568628]\n",
      "   [0.99215686 1.         0.99607843 ... 0.4392157  0.41568628\n",
      "    0.4       ]\n",
      "   ...\n",
      "   [0.99215686 1.         0.99607843 ... 0.31764707 0.29411766\n",
      "    0.33333334]\n",
      "   [0.99215686 1.         0.99607843 ... 0.3137255  0.29803923\n",
      "    0.33333334]\n",
      "   [0.99215686 1.         0.99607843 ... 0.3137255  0.32941177\n",
      "    0.3372549 ]]\n",
      "\n",
      "  [[1.         1.         1.         ... 0.4392157  0.43137255\n",
      "    0.4117647 ]\n",
      "   [0.99215686 1.         0.99607843 ... 0.43529412 0.40784314\n",
      "    0.38431373]\n",
      "   [0.99215686 1.         0.99607843 ... 0.41568628 0.38431373\n",
      "    0.36862746]\n",
      "   ...\n",
      "   [0.99215686 1.         0.99607843 ... 0.3137255  0.28627452\n",
      "    0.3254902 ]\n",
      "   [0.99215686 1.         0.99607843 ... 0.30980393 0.29411766\n",
      "    0.3254902 ]\n",
      "   [0.99215686 1.         0.99607843 ... 0.30980393 0.32156864\n",
      "    0.32941177]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.58431375 0.5647059  0.4392157  ... 0.60784316 0.54509807\n",
      "    0.59607846]\n",
      "   [0.61960787 0.46666667 0.24705882 ... 0.25882354 0.32941177\n",
      "    0.53333336]\n",
      "   [0.5921569  0.41568628 0.22745098 ... 0.15686275 0.2509804\n",
      "    0.49019608]\n",
      "   ...\n",
      "   [0.6313726  0.49411765 0.4392157  ... 0.49411765 0.50980395\n",
      "    0.61960787]\n",
      "   [0.6039216  0.50980395 0.43529412 ... 0.49803922 0.48235294\n",
      "    0.61960787]\n",
      "   [0.5921569  0.54509807 0.54509807 ... 0.50980395 0.54901963\n",
      "    0.62352943]]\n",
      "\n",
      "  [[0.54509807 0.52156866 0.42352942 ... 0.54509807 0.54509807\n",
      "    0.6156863 ]\n",
      "   [0.5803922  0.41568628 0.20392157 ... 0.21176471 0.34509805\n",
      "    0.5568628 ]\n",
      "   [0.5529412  0.34901962 0.16470589 ... 0.14509805 0.2627451\n",
      "    0.5019608 ]\n",
      "   ...\n",
      "   [0.5058824  0.3137255  0.2784314  ... 0.41960785 0.42352942\n",
      "    0.56078434]\n",
      "   [0.4745098  0.34901962 0.28627452 ... 0.4117647  0.38431373\n",
      "    0.5647059 ]\n",
      "   [0.49803922 0.44313726 0.44705883 ... 0.4509804  0.47843137\n",
      "    0.5882353 ]]\n",
      "\n",
      "  [[0.5019608  0.44705883 0.3764706  ... 0.47058824 0.45490196\n",
      "    0.5294118 ]\n",
      "   [0.5254902  0.3254902  0.15686275 ... 0.14901961 0.2509804\n",
      "    0.4627451 ]\n",
      "   [0.48235294 0.25490198 0.10980392 ... 0.11764706 0.20392157\n",
      "    0.41960785]\n",
      "   ...\n",
      "   [0.45882353 0.20392157 0.16862746 ... 0.31764707 0.32156864\n",
      "    0.45882353]\n",
      "   [0.4117647  0.23921569 0.17254902 ... 0.3019608  0.2784314\n",
      "    0.4627451 ]\n",
      "   [0.44313726 0.36862746 0.3647059  ... 0.35686275 0.3882353\n",
      "    0.5019608 ]]]\n",
      "\n",
      "\n",
      " [[[0.5137255  0.50980395 0.47843137 ... 0.5568628  0.5529412\n",
      "    0.6       ]\n",
      "   [0.45490196 0.4627451  0.49019608 ... 0.5019608  0.49803922\n",
      "    0.5294118 ]\n",
      "   [0.34117648 0.4509804  0.4862745  ... 0.48235294 0.49019608\n",
      "    0.54901963]\n",
      "   ...\n",
      "   [0.32941177 0.5764706  0.5803922  ... 0.53333336 0.54901963\n",
      "    0.54509807]\n",
      "   [0.30980393 0.56078434 0.5568628  ... 0.48235294 0.49803922\n",
      "    0.47843137]\n",
      "   [0.35686275 0.5568628  0.6039216  ... 0.47058824 0.48235294\n",
      "    0.49019608]]\n",
      "\n",
      "  [[0.44705883 0.4392157  0.40784314 ... 0.4745098  0.45882353\n",
      "    0.49019608]\n",
      "   [0.39215687 0.39215687 0.40784314 ... 0.42352942 0.4117647\n",
      "    0.43137255]\n",
      "   [0.28235295 0.36862746 0.38431373 ... 0.40392157 0.4117647\n",
      "    0.4627451 ]\n",
      "   ...\n",
      "   [0.29803923 0.47843137 0.4392157  ... 0.4509804  0.47058824\n",
      "    0.47058824]\n",
      "   [0.2627451  0.45490196 0.41960785 ... 0.39607844 0.41568628\n",
      "    0.4       ]\n",
      "   [0.29411766 0.44313726 0.46666667 ... 0.4        0.40784314\n",
      "    0.4117647 ]]\n",
      "\n",
      "  [[0.31764707 0.32156864 0.3019608  ... 0.34509805 0.3372549\n",
      "    0.3764706 ]\n",
      "   [0.28627452 0.2901961  0.30588236 ... 0.29411766 0.28627452\n",
      "    0.30980393]\n",
      "   [0.22352941 0.30588236 0.31764707 ... 0.27450982 0.28627452\n",
      "    0.34117648]\n",
      "   ...\n",
      "   [0.20392157 0.3529412  0.31764707 ... 0.33333334 0.33333334\n",
      "    0.3254902 ]\n",
      "   [0.16470589 0.3254902  0.28627452 ... 0.29411766 0.2901961\n",
      "    0.25882354]\n",
      "   [0.1882353  0.30588236 0.3254902  ... 0.23529412 0.25490198\n",
      "    0.27450982]]]\n",
      "\n",
      "\n",
      " [[[0.34901962 0.42745098 0.4745098  ... 0.57254905 0.5803922\n",
      "    0.5764706 ]\n",
      "   [0.25882354 0.26666668 0.2784314  ... 0.56078434 0.5647059\n",
      "    0.5647059 ]\n",
      "   [0.23921569 0.24705882 0.22352941 ... 0.54901963 0.56078434\n",
      "    0.5686275 ]\n",
      "   ...\n",
      "   [0.49803922 0.37254903 0.29803923 ... 0.50980395 0.53333336\n",
      "    0.54509807]\n",
      "   [0.45882353 0.3372549  0.27058825 ... 0.5176471  0.5254902\n",
      "    0.5411765 ]\n",
      "   [0.40392157 0.30980393 0.22352941 ... 0.5137255  0.5137255\n",
      "    0.5176471 ]]\n",
      "\n",
      "  [[0.39607844 0.4745098  0.5137255  ... 0.6313726  0.6313726\n",
      "    0.6156863 ]\n",
      "   [0.28627452 0.29803923 0.30588236 ... 0.61960787 0.6117647\n",
      "    0.6039216 ]\n",
      "   [0.2509804  0.2627451  0.23529412 ... 0.60784316 0.6117647\n",
      "    0.60784316]\n",
      "   ...\n",
      "   [0.5647059  0.4392157  0.36862746 ... 0.5764706  0.5921569\n",
      "    0.6       ]\n",
      "   [0.52156866 0.40392157 0.3372549  ... 0.5803922  0.58431375\n",
      "    0.5921569 ]\n",
      "   [0.47058824 0.3764706  0.29803923 ... 0.58431375 0.5803922\n",
      "    0.5764706 ]]\n",
      "\n",
      "  [[0.27450982 0.37254903 0.44313726 ... 0.5568628  0.56078434\n",
      "    0.54901963]\n",
      "   [0.21176471 0.22352941 0.24313726 ... 0.54509807 0.54509807\n",
      "    0.5372549 ]\n",
      "   [0.19215687 0.20392157 0.18039216 ... 0.53333336 0.5411765\n",
      "    0.54509807]\n",
      "   ...\n",
      "   [0.49019608 0.3882353  0.3372549  ... 0.52156866 0.5372549\n",
      "    0.53333336]\n",
      "   [0.44705883 0.3529412  0.30588236 ... 0.5254902  0.5372549\n",
      "    0.5372549 ]\n",
      "   [0.40784314 0.33333334 0.26666668 ... 0.52156866 0.5294118\n",
      "    0.5254902 ]]]]\n",
      "<class 'numpy.ndarray'>\n",
      "None\n",
      "<class 'NoneType'>\n",
      "torch.Size([16667, 3, 32, 32])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [16667, 0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-e8bd136fde87>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(model, opt, epoch, loss_fn, lr_scheduler)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuned_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m#     gs.fit(train_set, val_set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m     \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;31m#     gs.fit(train_dataset, val_dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    689\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 691\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1001\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1004\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m         \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 score = scorer._score(cached_call, estimator,\n\u001b[0;32m---> 87\u001b[0;31m                                       *args, **kwargs)\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/metrics/_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0;32m--> 212\u001b[0;31m                                                  **self._kwargs)\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Pytorch-1.0.0/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [16667, 0]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "opt = optim.SGD(model.parameters(), lr=1e-1, momentum=0.9, weight_decay=1e-4, nesterov=False)\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "lr_scheduler= optim.lr_scheduler.MultiStepLR(opt, milestones=[91, 137], gamma=0.1)\n",
    "history = main(model, opt, epoch=180, loss_fn=loss_fn, lr_scheduler=lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
